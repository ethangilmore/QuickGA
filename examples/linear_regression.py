import random
from quickga import Organism, FloatTrait

# create a random slope and intercept for a line
m = random.uniform(-5,5)
b = random.uniform(-5,5)

# creates all the poins on the line on the interval [-100, 100]
def generate_points():
    f = lambda x: m*x+b
    xs = range(-10, 10)
    ys = [f(x) for x in xs]
    points = [(xs[i], ys[i]) for i in range(len(xs))]
    return points

points = generate_points()

# create an organism with traits for slope and y-intercept
class Regression(Organism):
    
    def __init__(self):
        super().__init__()
        # the line below creates a class attribute self.m which will be a random float on the interval [-5,5) (as defined by FloatTrait)
        self.add_trait('m', FloatTrait(-5, 5, 0.05))
        # the line below creates a similar class attribute self.b
        self.add_trait('b', FloatTrait(-5, 5, 0.05))

    def evaluate(self):
        # note that self.m and self.b are class attributes but created by the self.add_trait method in __init__
        # their values are defined by the associated trait. In this case floats (becuase they are generated by the FloatTrait object)
        f = lambda x: self.m * x + self.b

        # sum the squared difference for each of the actual points to the line created from this organisms slope and y-intercept
        sum_squared_error = sum([(point[1]-f(point[0]))**2 for point in points])

        # we need to invert the value so that higher error means lower fitness
        return 1/sum_squared_error

# do the magic
generations = Regression.evolve(population_size=100, generations=200)
# retrieves the most fit Regression object from the last generation
most_fit = generations[-1]['most_fit']
# get the slope and y-intercept values from the most fit object
m_fit, b_fit = most_fit.m, most_fit.b

print(f"Points were created from the line {round(m, 2)}X + {round(b,2)}")
print(f"Line of best fit is {round(m_fit, 2)}X + {round(b_fit, 2)}")